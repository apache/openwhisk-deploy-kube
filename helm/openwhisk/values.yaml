#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#


# This file defines the default values for all variables
# used in the OpenWhisk Helm Chart.  The variables are grouped
# by component into subtrees.
#
# You _MUST_ override the default value of some of the whisk.ingress variables
# to reflect your specific Kubernetes cluster.  For details, see the appropriate
# one of these files:
#   docs/k8s-docker-for-mac.md
#   docs/k8s-aws.md
#   docs/k8s-ibm-public.md
#   docs/k8s-ibm-private.md
#   docs/k8s-google.md
#   docs/k8s-diy.md (for do-it-yourself clusters).
#
# Production deployments _MUST_ override the default credentials
# that are used in whisk.auth and db.auth.
#
# The file docs/configurationChoices.md discusses other common
# configuration options for OpenWhisk and which variables to override
# to enable them.
#
# The file values-metadata.yaml contains a description of each
# of these variables and must also be updated when any changes are
# made to this file.

# Overall configuration of OpenWhisk deployment
whisk:
  # Ingress defines how to access OpenWhisk from outside the Kubernetes cluster.
  # Only a subset of the values are actually used on any specific type of cluster.
  # See the "Configuring OpenWhisk section" of the docs/k8s-*.md that matches
  # your cluster type for details on what values to provide and how to get them.
  ingress:
    awsSSL: "false"
    apiHostName: ""
    apiHostPort: 31001
    apiHostProto: "https"
    type: NodePort
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    domain: "domain"
    tls:
      enabled: false
      secretenabled: false
      createsecret: false
      secretname: "ow-ingress-tls-secret"
      secrettype: "type"
      crt: "crt"
      key: "key"
  # Production deployments _MUST_ override these default auth values
  auth:
    system: "789c46b1-71f6-4ed5-8c54-816aa4f8c502:abczO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP"
    guest: "23bc46b1-71f6-4ed5-8c54-816aa4f8c502:123zO3xZCLrMN6v2BKK1dXYFpXlPkccOFqm12CdAsMgRU4VrNZ9lyGVCGuMDGIwP"
  systemNameSpace: "/whisk.system"
  limits:
    actionsInvokesPerminute: 60
    actionsInvokesConcurrent: 30
    triggersFiresPerminute: 60
    actionsSequenceMaxlength: 50
    actions:
      time:
        min: "100ms"
        max: "5m"
        std: "1m"
      memory:
        min: "128m"
        max: "512m"
        std: "256m"
      concurrency:
        min: 1
        max: 1
        std: 1
      log:
        min: "0m"
        max: "10m"
        std: "10m"
    activation:
      payload:
        max: "1048576"
  loadbalancer:
    blackboxFraction: "10%"
    timeoutFactor: 2
  # Kafka configuration. For all sub-fields a value of "" means use the default from application.conf
  kafka:
    replicationFactor: ""
    topics:
      cacheInvalidation:
        segmentBytes: ""
        retentionBytes: ""
        retentionMs: ""
      completed:
        segmentBytes: ""
        retentionBytes: ""
        retentionMs: ""
      events:
        segmentBytes: ""
        retentionBytes: ""
        retentionMs: ""
      health:
        segmentBytes: ""
        retentionBytes: ""
        retentionMs: ""
      invoker:
        segmentBytes: ""
        retentionBytes: ""
        retentionMs: ""
  containerPool:
    userMemory: "2048m"
  runtimes: "runtimes.json"
  testing:
    includeTests: true
    includeSystemTests: false
  versions:
    openwhisk:
      buildDate: "2020-06-17-15:21:13Z"
      buildNo: "20200617a"
      gitTag: "71b7d564ff60bf6e89be5410ffcf59f785d17a4a"
    openwhiskCli:
      tag: "1.0.0"
    openwhiskCatalog:
      gitTag: "0.11.0"
    openwhiskPackageAlarms:
      gitTag: "2.0.0-incubating"
    openwhiskPackageCloudant:
      gitTag: "2.0.0-incubating"
    openwhiskPackageKafka:
      gitTag: "2.0.0-incubating"

k8s:
  domain: cluster.local
  dns: kube-dns.kube-system
  persistence:
    enabled: true
    hasDefaultStorageClass: true
    explicitStorageClass: null

# Images used to run auxillary tasks/jobs
utility:
  imageName: "openwhisk/ow-utils"
  imageTag: "71b7d56"
  imagePullPolicy: "IfNotPresent"

# Docker registry
docker:
  registry:
    name: ""
    username: ""
    password: ""
  timezone: "UTC"

# zookeeper configurations
zookeeper:
  imageName: "zookeeper"
  imageTag: "3.4"
  imagePullPolicy: "IfNotPresent"
  # Note: Zookeeper's quorum protocol is designed to have an odd number of replicas.
  replicaCount: 1
  restartPolicy: "Always"
  port: 2181
  serverPort: 2888
  leaderElectionPort: 3888
  persistence:
    size: 256Mi
  # Default values for entries in zoo.cfg (see Apache Zookeeper documentation for semantics)
  config:
    tickTime: 2000
    initLimit: 5
    syncLimit: 2
    dataDir: "/data"
    dataLogDir: "/datalog"

# kafka configurations
kafka:
  imageName: "wurstmeister/kafka"
  imageTag: "2.12-2.3.1"
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  port: 9092
  persistence:
    size: 512Mi

# Database configuration
db:
  external: false
  # Should we run a Job to wipe and re-initialize the database when the chart is deployed?
  # This should always be true if external is false.
  wipeAndInit: true
  imageName: "apache/couchdb"
  imageTag: "2.3"
  imagePullPolicy: "IfNotPresent"
  # NOTE: must be 1 (because initdb.sh enables single node mode)
  replicaCount: 1
  restartPolicy: "Always"
  host: null
  port: 5984
  provider: "CouchDB"
  protocol: "http"
  # Production deployments _MUST_ override the default user/password values
  auth:
    username: "whisk_admin"
    password: "some_passw0rd"
  dbPrefix: "test_"
  activationsTable: "test_activations"
  actionsTable: "test_whisks"
  authsTable: "test_subjects"
  persistence:
    size: 2Gi

# Nginx configurations
nginx:
  imageName: "nginx"
  imageTag: "1.17"
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  httpPort: 80
  httpsPort: 443
  httpsNodePort: 31001

# Controller configurations
controller:
  imageName: "openwhisk/controller"
  imageTag: "71b7d56"
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  port: 8080
  options: ""
  jvmHeapMB: "1024"
  jvmOptions: ""

# Invoker configurations
invoker:
  imageName: "openwhisk/invoker"
  imageTag: "71b7d56"
  imagePullPolicy: "IfNotPresent"
  restartPolicy: "Always"
  port: 8080
  options: ""
  jvmHeapMB: "512"
  jvmOptions: ""
  containerFactory:
    useRunc: false
    impl: "kubernetes"
    enableConcurrency: false
    networkConfig:
      name: "bridge"
      dns:
        inheritInvokerConfig: true
        overrides:          # NOTE: if inheritInvokerConfig is true, all overrides are ignored
          # Nameservers, search, and options are space-separated lists
          # eg nameservers: "1.2.3.4 1.2.3.5 1.2.3.6" is a list of 3 nameservers
          nameservers: ""
          search: ""
          options: ""
    kubernetes:
      isolateUserActions: true
      replicaCount: 1

# API Gateway configurations
apigw:
  imageName: "openwhisk/apigateway"
  imageTag: "1.0.0"
  imagePullPolicy: "IfNotPresent"
  # NOTE: setting replicaCount > 1 is not tested and may not work
  replicaCount: 1
  restartPolicy: "Always"
  apiPort: 9000
  mgmtPort: 8080

# Redis (used by apigateway)
redis:
  external: false
  imageName: "redis"
  imageTag: "4.0"
  imagePullPolicy: "IfNotPresent"
  # NOTE: setting replicaCount > 1 will not work; need to add redis cluster configuration
  replicaCount: 1
  restartPolicy: "Always"
  host: null
  port: 6379
  persistence:
    size: 256Mi

# User-events configuration
user_events:
  imageName: "openwhisk/user-events"
  imageTag: "71b7d56"
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  port: 9095

# Prometheus configuration
prometheus:
  imageName: "prom/prometheus"
  imageTag: v2.14.0
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  port: 9090
  persistence:
    size: 1Gi
  persistentVolume:
    mountPath: /prometheus/

# Grafana configuration
grafana:
  imageName: "grafana/grafana"
  imageTag: "6.3.0"
  imagePullPolicy: "IfNotPresent"
  replicaCount: 1
  restartPolicy: "Always"
  port: 3000
  adminPassword: "admin"
  dashboards:
  - https://raw.githubusercontent.com/apache/openwhisk/master/core/monitoring/user-events/compose/grafana/dashboards/openwhisk_events.json
  - https://raw.githubusercontent.com/apache/openwhisk/master/core/monitoring/user-events/compose/grafana/dashboards/global-metrics.json
  - https://raw.githubusercontent.com/apache/openwhisk/master/core/monitoring/user-events/compose/grafana/dashboards/top-namespaces.json

# Metrics
metrics:
  # set true to enable prometheus exporter
  prometheusEnabled: false
  # passing prometheus-enabled by a config file, required by openwhisk
  whiskconfigFile: "whiskconfig.conf"
  # set true to enable Kamon
  kamonEnabled: false
  # set true to enable Kamon tags
  kamonTags: false
  # set true to enable user metrics
  userMetricsEnabled: false

# Configuration of OpenWhisk event providers
providers:
  # CouchDB instance used by all enabled providers to store event/configuration data.
  db:
    external: false
    # Define the rest of these values if you are using external couchdb instance
    host: "10.10.10.10"
    port: 5984
    protocol: "http"
    username: "admin"
    password: "secret"
  # Alarm provider configurations
  alarm:
    enabled: true
    imageName: "openwhisk/alarmprovider"
    imageTag: "2.1.0"
    imagePullPolicy: "IfNotPresent"
    # NOTE: replicaCount > 1 doesn't work because of the PVC
    replicaCount: 1
    restartPolicy: "Always"
    apiPort: 8080
    dbPrefix: "alm"
    persistence:
      size: 1Gi
  # Cloudant provider configurations
  cloudant:
    enabled: true
    imageName: "openwhisk/cloudantprovider"
    imageTag: "2.0.0-incubating"
    imagePullPolicy: "IfNotPresent"
    # NOTE: replicaCount > 1 doesn't work because of the PVC
    replicaCount: 1
    restartPolicy: "Always"
    apiPort: 8080
    dbPrefix: "cldt"
    persistence:
      size: 1Gi
  # Kafka provider configurations
  kafka:
    enabled: true
    imageName: "openwhisk/kafkaprovider"
    imageTag: "2.0.0-incubating"
    imagePullPolicy: "IfNotPresent"
    # NOTE: setting replicaCount > 1 has not been tested and may not work
    replicaCount: 1
    restartPolicy: "Always"
    apiPort: 8080
    dbPrefix: "kp"


# Used to define pod affinity and anti-affinity for the Kubernetes scheduler.
# If affinity.enabled is true, then all of the deployments for the OpenWhisk
# microservices will use node and pod affinity directives to inform the
# scheduler how to best distribute the pods on the available nodes in the cluster.
affinity:
  enabled: true
  coreNodeLabel: core
  edgeNodeLabel: edge
  invokerNodeLabel: invoker
  providerNodeLabel: provider

# Used to define toleration for the Kubernetes scheduler.
# If tolerations.enabled is true, then all of the deployments for the OpenWhisk
# microservices will add tolerations for key openwhisk-role with specified value and effect NoSchedule.
toleration:
  enabled: true
  coreValue: core
  edgeValue: edge
  invokerValue: invoker

# Used to define the probes timing settings so that you can more precisely control the
# liveness and readiness checks.
# initialDelaySeconds - Initial wait time to start probes after container has started
# periodSeconds - Frequency to perform the probe, defaults to 10, minimum value is 1
# timeoutSeconds - Probe will timeouts after defined seconds, defaults to 1 second,
#                  minimum value is 1
# for more information please refer - https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
# Note - for now added probes settings for zookeeper and controller only.
#        in future all components probes timing settings should be
#        configured here if any.

probes:
  zookeeper:
    livenessProbe:
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 1
    readinessProbe:
      initialDelaySeconds: 5
      periodSeconds: 10
      timeoutSeconds: 1
  controller:
    livenessProbe:
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 1
    readinessProbe:
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 1

# Pod Disruption Budget allows Pods to survive Voluntary and Involuntary Disruptions.
# for more information refer - https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
# Pod Disruptions budgets currently supported for the pods which are managed
# by one of Kubernetes built-in controllers (Deployment, ReplicationController,
# ReplicaSet, StatefulSet).
# Caveats -
# - You can specify numbers of maxUnavailable Pods for now as integer. % values are not
# supported.
# - minAvailable is not supported
# - PDB only applicable when replicaCount is greater than 1.
# - Only zookeeper, kafka, invoker and controller pods are supported for PDB for now.
# - Invoker PDB only applicable if containerFactory implementation is of type "kubernetes"

pdb:
  enable: false
  zookeeper:
    maxUnavailable: 1
  kafka:
    maxUnavailable: 1
  controller:
    maxUnavailable: 1
  invoker:
    maxUnavailable: 1
